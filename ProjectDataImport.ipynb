{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve,f1_score,auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproduceable results\n",
    "np.random.seed(500)\n",
    "# Read in to Pandas DataFrame and drop the first row(which contained column names as I have assigned new names)\n",
    "reviews = pd.read_csv(r\"rt_reviews.csv\", names = ['target', 'review'], encoding = 'latin-1')\n",
    "reviews = reviews.iloc[1:]\n",
    "reviews = reviews.iloc[:480000] # Choose num here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reviews.shape[0]):\n",
    "    #if(isinstance(reviews['target'].values[i],)):\n",
    "    if(reviews['target'].values[i] == '0'):\n",
    "        reviews['target'].values[i] = 0\n",
    "    elif(reviews['target'].values[i] == '1'):\n",
    "        reviews['target'].values[i] = 1\n",
    "for i in range(reviews.shape[0]):\n",
    "    if(isinstance(reviews['target'].values[i],str)):\n",
    "        print(\"Caught: \",reviews['target'].values[i])\n",
    "    if(reviews['target'].values[i] != 0 and reviews['target'].values[i] != 1):\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data is of shape(480000,2) The first column is the target, the second in the review\n",
    "\n",
    "# Make data smaller for ease of implementation\n",
    "reviews = reviews.iloc[:480000] # Choose num here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove and row where either datafield is blank, no rows contained blank data so the shape remains 480000,2 \n",
    "reviews.dropna(inplace = True)\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>it would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>if there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             review\n",
       "1      1   manakamana doesn't answer any questions, yet ...\n",
       "2      1   wilfully offensive and powered by a chest-thu...\n",
       "3      0   it would be difficult to imagine material mor...\n",
       "4      0   despite the gusto its star brings to the role...\n",
       "5      0   if there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all text to lowercase so all words recognized the same \n",
    "reviews['review'] = [entry.lower() for entry in reviews['review']]\n",
    "\n",
    "# Can now been seen to contain no capital letters\n",
    "reviews.head()\n",
    "#type(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize each review: this process converts each review into a set of words. \n",
    "reviews['review'] = [word_tokenize(entry) for entry in reviews['review']]\n",
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[manakamana, does, n't, answer, any, questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[wilfully, offensive, and, powered, by, a, che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[it, would, be, difficult, to, imagine, materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[despite, the, gusto, its, star, brings, to, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[if, there, was, a, good, idea, at, the, core,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                             review\n",
       "1      1  [manakamana, does, n't, answer, any, questions...\n",
       "2      1  [wilfully, offensive, and, powered, by, a, che...\n",
       "3      0  [it, would, be, difficult, to, imagine, materi...\n",
       "4      0  [despite, the, gusto, its, star, brings, to, t...\n",
       "5      0  [if, there, was, a, good, idea, at, the, core,..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps are stemming/lemmenting which reduces words to their root so that words such as 'loving' and 'loved'\n",
    "# both reduce to 'love'\n",
    "\n",
    "# Creating tags so that lemmatizer can understand verbs from nouns from adjectives \n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index,entry in enumerate(reviews['review']):\n",
    "    index = index+1 # Index seems to off by one, this fixes it\n",
    "    # Words that follow the rules will end up in this list\n",
    "    Final_words = []\n",
    "    \n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "        reviews.loc[index, 'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>review</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479996</th>\n",
       "      <td>0</td>\n",
       "      <td>[zemeckis, seems, unable, to, admit, that, the...</td>\n",
       "      <td>['zemeckis', 'seem', 'unable', 'admit', 'motio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479997</th>\n",
       "      <td>1</td>\n",
       "      <td>[movies, like, the, kids, are, all, right, --,...</td>\n",
       "      <td>['movie', 'like', 'kid', 'right', 'beautifully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479998</th>\n",
       "      <td>0</td>\n",
       "      <td>[film-savvy, audiences, soon, will, catch, ont...</td>\n",
       "      <td>['audience', 'soon', 'catch', 'onto', 'winterb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479999</th>\n",
       "      <td>1</td>\n",
       "      <td>[an, odd, yet, enjoyable, film, .]</td>\n",
       "      <td>['odd', 'yet', 'enjoyable', 'film']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480000</th>\n",
       "      <td>1</td>\n",
       "      <td>[no, other, animation, studio, ,, even, our, b...</td>\n",
       "      <td>['animation', 'studio', 'even', 'beloved', 'pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                             review  \\\n",
       "479996      0  [zemeckis, seems, unable, to, admit, that, the...   \n",
       "479997      1  [movies, like, the, kids, are, all, right, --,...   \n",
       "479998      0  [film-savvy, audiences, soon, will, catch, ont...   \n",
       "479999      1                 [an, odd, yet, enjoyable, film, .]   \n",
       "480000      1  [no, other, animation, studio, ,, even, our, b...   \n",
       "\n",
       "                                               text_final  \n",
       "479996  ['zemeckis', 'seem', 'unable', 'admit', 'motio...  \n",
       "479997  ['movie', 'like', 'kid', 'right', 'beautifully...  \n",
       "479998  ['audience', 'soon', 'catch', 'onto', 'winterb...  \n",
       "479999                ['odd', 'yet', 'enjoyable', 'film']  \n",
       "480000  ['animation', 'studio', 'even', 'beloved', 'pi...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test splits \n",
    "test_s = .25\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(reviews['text_final'], reviews['target'], test_size=test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_x Shape:  (360000,)\n",
      "\n",
      "train_y Shape:  (360000,)\n",
      "\n",
      "test_x Shape:  (120000,)\n",
      "\n",
      "test_y Shape:  (120000,)\n",
      "360649    ['intimation', 'abu', 'ghraib', 'allusion', 'w...\n",
      "285349    ['occasionally', 'stir', 'peek', 'place', 'phe...\n",
      "59650     ['glum', 'muddy', 'muddle', 'gory', 'tell', 'b...\n",
      "178735    ['repo', 'men', 'set', 'put', 'motion', 'premi...\n",
      "84349     ['struggle', 'find', 'balance', 'contemporary'...\n",
      "                                ...                        \n",
      "429064    ['conventional', 'storytelling', 'far', 'less'...\n",
      "223840    ['know', 'young', 'beautiful', 'hip', 'could',...\n",
      "338243    ['fun', 'science', 'fiction', 'action', 'film'...\n",
      "420399    ['david', 'russell', 'film', 'fizz', 'energy',...\n",
      "292302    ['fool', 'title', 'bouncy', 'comedy', 'tonally...\n",
      "Name: text_final, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ntrain_x Shape: \", train_x.shape)\n",
    "print(\"\\ntrain_y Shape: \", train_y.shape)\n",
    "print(\"\\ntest_x Shape: \", test_x.shape)\n",
    "print(\"\\ntest_y Shape: \", test_y.shape)\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "train_y = Encoder.fit_transform(train_y)\n",
    "test_y = Encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f = 10000\n",
    "Tfidf_vect = TfidfVectorizer(max_features=max_f)\n",
    "Tfidf_vect.fit(reviews['text_final'])\n",
    "train_x_Tfidf = Tfidf_vect.transform(train_x)\n",
    "test_x_Tfidf = Tfidf_vect.transform(test_x)\n",
    "print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8673)\t0.24114998547474012\n",
      "  (0, 8337)\t0.2758537506369254\n",
      "  (0, 7948)\t0.20689398482346452\n",
      "  (0, 7336)\t0.26126901320769347\n",
      "  (0, 7112)\t0.24557843103987745\n",
      "  (0, 5076)\t0.3518463599655684\n",
      "  (0, 4227)\t0.2515952044714167\n",
      "  (0, 4185)\t0.38844645665124905\n",
      "  (0, 3796)\t0.15917919526995308\n",
      "  (0, 3336)\t0.19395978614723236\n",
      "  (0, 3281)\t0.3058363629916194\n",
      "  (0, 3190)\t0.21311210728582683\n",
      "  (0, 2132)\t0.22096420787578103\n",
      "  (0, 1636)\t0.17444563207480088\n",
      "  (0, 303)\t0.27426597560488863\n",
      "  (1, 9018)\t0.9204590189459473\n",
      "  (1, 8996)\t0.1847324547643638\n",
      "  (1, 6794)\t0.21140368794485123\n",
      "  (1, 6553)\t0.1332403280894473\n",
      "  (1, 4415)\t0.1585775172860864\n",
      "  (1, 2684)\t0.17617542763708552\n",
      "  (2, 8180)\t0.3056480339958997\n",
      "  (2, 7636)\t0.3113245314385503\n",
      "  (2, 5471)\t0.33623796881690776\n",
      "  (2, 5207)\t0.21967126334406667\n",
      "  :\t:\n",
      "  (359995, 1363)\t0.20051537223703397\n",
      "  (359996, 9957)\t0.4550029497266634\n",
      "  (359996, 8220)\t0.6035883353923267\n",
      "  (359996, 2903)\t0.49616807065821894\n",
      "  (359996, 2577)\t0.4271658726743701\n",
      "  (359997, 8244)\t0.32910754096279926\n",
      "  (359997, 7910)\t0.46201483612941274\n",
      "  (359997, 7676)\t0.5136544761627032\n",
      "  (359997, 4075)\t0.27092877499234524\n",
      "  (359997, 3018)\t0.4031130388696676\n",
      "  (359997, 3014)\t0.4224773053906674\n",
      "  (359998, 9957)\t0.4060816858831819\n",
      "  (359998, 3068)\t0.6659537167907659\n",
      "  (359998, 2419)\t0.6257821597671487\n",
      "  (359999, 9896)\t0.19702222085007814\n",
      "  (359999, 8684)\t0.31309704121063553\n",
      "  (359999, 8484)\t0.17281110115508128\n",
      "  (359999, 5799)\t0.2681353968491184\n",
      "  (359999, 5036)\t0.24946429841258277\n",
      "  (359999, 4257)\t0.2543677638534384\n",
      "  (359999, 3963)\t0.27332269905308354\n",
      "  (359999, 3712)\t0.31565846317546375\n",
      "  (359999, 1123)\t0.43747488388453454\n",
      "  (359999, 313)\t0.4464901591770513\n",
      "  (359999, 92)\t0.2633885430625419\n"
     ]
    }
   ],
   "source": [
    "print(train_x_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Attempt at classifier is Naive Bays \n",
    "nbm = naive_bayes.MultinomialNB()\n",
    "nbm.fit(train_x_Tfidf, train_y)\n",
    "\n",
    "#Gaussian Naive Bayes\n",
    "nbg = naive_bayes.GaussianNB()\n",
    "#nbg.fit(train_x_Tfidf.toarray(), train_y)\n",
    "\n",
    "#Bernoulli Naive Bayes\n",
    "nbb = naive_bayes.BernoulliNB()\n",
    "nbb.fit(train_x_Tfidf, train_y)\n",
    "\n",
    "# predict the target on validation data\n",
    "pred_nbm = nbm.predict(test_x_Tfidf)\n",
    "#pred_nbg = nbg.predict(test_x_Tfidf.toarray())\n",
    "pred_nbb = nbb.predict(test_x_Tfidf)\n",
    "\n",
    "# output accuracy just to show it works\n",
    "print(\"NB Multinomial: Accuracy: \", accuracy_score(pred_nbm, test_y))\n",
    "#print(\"NB Gaussian: Accuracy: \", accuracy_score(pred_nbg, test_y))\n",
    "print(\"NB Bernoulli: Accuracy: \", accuracy_score(pred_nbb, test_y))\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(train_x_Tfidf, train_y)\n",
    "pred_svm = svm.predict(test_x_Tfidf)\n",
    "print(\"SVM: Accuracy: \", accuracy_score(pred_svm, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Analysis\n",
    "\n",
    "#Predict Probability\n",
    "nbm_probs = nbm.predict_proba(test_x_Tfidf)\n",
    "nbm_probs = nbm_probs[:,1]\n",
    "#nbg_probs = nbg.predict_proba(test_x_Tfidf.toarray())\n",
    "#nbg_probs = nbg_probs[:,1]\n",
    "nbb_probs = nbb.predict_proba(test_x_Tfidf)\n",
    "nbb_probs = nbb_probs[:,1]\n",
    "svm_probs = svm.predict_proba(test_x_Tfidf)\n",
    "svm_probs = svm_probs[:,1]\n",
    "\n",
    "#Classification Report\n",
    "print(classification_report(test_y, pred_nbm, labels=[0,1]))\n",
    "#print(classification_report(test_y, pred_nbg, labels=[0,1]))\n",
    "print(classification_report(test_y, pred_nbb, labels=[0,1]))\n",
    "print(classification_report(test_y, pred_svm, labels=[0,1]))\n",
    "\n",
    "#Calculate precision-recall\n",
    "precision_nbm, recall_nbm, thresholds_nbm = precision_recall_curve(test_y, nbm_probs)\n",
    "#precision_nbg, recall_nbg, thresholds_nbg = precision_recall_curve(test_y, nbg_probs)\n",
    "precision_nbb, recall_nbb, thresholds_nbb = precision_recall_curve(test_y, nbb_probs)\n",
    "precision_svm, recall_svm, thresholds_svm = precision_recall_curve(test_y, svm_probs)\n",
    "\n",
    "#Calculate F1\n",
    "f1_nbm = f1_score(test_y, pred_nbm)\n",
    "#f1_nbg = f1_score(test_y, pred_nbg)\n",
    "f1_nbb = f1_score(test_y, pred_nbb)\n",
    "f1_svm = f1_score(test_y, pred_svm)\n",
    "\n",
    "#Calculate precision recal auc\n",
    "# auc_nb = auc(recall_nb, precision_nb)\n",
    "# auc_svm = auc(recall_svm, precision_svm)\n",
    "\n",
    "# summarize scores\n",
    "print(\"Test Split: \", test_s)\n",
    "print(\"Max Features: \", max_f)\n",
    "print('Naive-Bayes-Multinomial: f1=%.3f' % (f1_nbm))\n",
    "print(\"Accuracy: \", accuracy_score(pred_nbm, test_y))\n",
    "#print('Naive-Bayes-Gaussian: f1=%.3f' % (f1_nbg))\n",
    "#print(\"Accuracy: \", accuracy_score(pred_nbg, test_y))\n",
    "print('Naive-Bayes-Bernoulli: f1=%.3f' % (f1_nbb))\n",
    "print(\"Accuracy: \", accuracy_score(pred_nbb, test_y))\n",
    "print('Support Vector Machine: f1=%.3f' % (f1_svm))\n",
    "print(\"Accuracy: \", accuracy_score(pred_svm, test_y))\n",
    "\n",
    "\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(recall_nbm, precision_nbm, marker='.', label='Naive-Bayes Multinomial')\n",
    "#pyplot.plot(recall_nbg, precision_nbg, marker='.', label='Naive-Bayes Gaussian')\n",
    "pyplot.plot(recall_nbb, precision_nbb, marker='.', label='Naive-Bayes Bernoulli')\n",
    "pyplot.plot(recall_svm, precision_svm, marker='.', label='SVM')\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
